# Read Note for [Data-Dependent Stability of Stochastic Gradient Descent](https://arxiv.org/pdf/1703.01678.pdf)

## Summary
The autors employ the algorithm stability of SGD to develop generalization bound. 
1. In the non-convex case, they prove that the expected curvature of the objective function aroound the initializationpoint has crucial influence on the generalization error.
2. In the convex case, they show that the bound depends on the risk at the initilization point.

## Stability of SGD
1. ![Notation](https://github.com/HJSang/ReadingNote/blob/master/Screen%20Shot%202019-03-03%20at%2009.25.28.png)

